{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that sample $x \\in X$ can belong to one of the K class, where $k > 2$. Then there are several ways to classify it:\n",
    "\n",
    "* classifier which support multiclass classification\n",
    "* reduction to the set of binary classification problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Multiclass logistic regression\n",
    "\n",
    "In logistic regression we define a linear model as follows:\n",
    "$$b(x)=\\sigma(\\langle w,x \\rangle)= \\frac{1}{1+ exp(-\\langle w,x \\rangle)}$$\n",
    "\n",
    "Assume, that for each class $k$ we build linear model $b_k(x)$, which answers the question, if object $x$ belongs to class $k$ or not (or measures the probability of belonging). Thus we can construct a following vector:\n",
    "\n",
    "$$(b_1(x), b_2(x), \\dots, b_k(x))$$\n",
    "\n",
    "A distinctive feature of logistic regression is that it returns the probability that an object belongs to a certain class. How to make probability from the previous vector?\n",
    "\n",
    "Use a soft-max operator!\n",
    "\n",
    "$$SoftMax \\left(x_1, \\dots, x_k \\right) = \\left(\\frac{\\exp \\left(x_1\\right)}{\\sum\\limits^{k}_{i=1}\\exp \\left(x_i\\right)},\\dots, \\frac{\\exp \\left(x_k \\right)}{\\sum\\limits^{k}_{i=1}\\exp \\left(x_i \\right)} \\right)$$\n",
    "\n",
    "Each parameter here will be a probability of belonging to a certain class, i.e the probability of belonhing to class $k$ is:\n",
    "$$P(y=k| x,w) = \\frac{\\exp \\left( \\langle w_k,x \\rangle + w_{0k} \\right)}{\\sum\\limits^{k}_{i=1}\\exp \\left( \\langle w_j,x \\rangle + w_{0j} \\right)}$$\n",
    "\n",
    "Objective fucntion here will be also log - likelihood:\n",
    "\n",
    "$$\\sum\\limits_{i=1}^{l}log(P(y=y_i|x,w)) \\to max_{w_1, \\dots, w_K}$$\n",
    "\n",
    "```python\n",
    "\n",
    "sklearn.linear_model.LogisticRegression(multi_class='multinomial')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "\n",
    "# 1.2 Multiclass SVM\n",
    "\n",
    "[Paper about multiclass SVM](http://jmlr.csail.mit.edu/papers/volume2/crammer01a/crammer01a.pdf)\n",
    "\n",
    "Consider following algorithm:\n",
    "$$a(x) = argmax_k(\\langle w_k, x \\rangle), k= 1, \\dots K$$\n",
    "\n",
    "Task of multi-class classification with SVM can be written as follows:\n",
    "\n",
    "\\begin{equation}\n",
    " \\begin{cases}\n",
    "   \\frac{1}{2}||W||^2 + C \\sum\\limits_i^l \\varepsilon_i \\to min_w \\\\\n",
    "   \\langle w_{y_i}, x_i \\rangle + \\left[ y_i=k \\right] - \\langle w_{k}, x_i \\rangle \\geq 1 - \\varepsilon_i, i = 1, \\dots, l; k=1, \\dots,K \\\\\n",
    "   \\varepsilon_i \\geq 0, i = 1, \\dots, l\n",
    " \\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "```python\n",
    "\n",
    "sklearn.svm.LinearSVC(multi_class=”crammer_singer”)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "\n",
    "# 1.3 Reduction to the set of binary classifiers \n",
    "## 1.3.1 One-vs-All (One-vs-Rest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Idea:** \n",
    "\n",
    "Create set of classifiers, where $k$-th classifier will answer the question if sample belongs to $k$ or not. \n",
    "    \n",
    "$$b_k(x)= \\langle w_k,x \\rangle + w_{0k}$$\n",
    "\n",
    "We will train classifier on the sample: $(x_i, 2I(y_i=k) -1)$. \n",
    "\n",
    "All in all we will have $K$ classifiers, equal to the number of classes. Final classifier defines as follows:\n",
    "\n",
    "$$a(x) = argmax_{b_1, \\dots, b_k}(b_k(x))$$\n",
    "\n",
    "**Problem**: each classifeir trains on its own sample, thus answers may have different scale, therefore they cannot be compared. \n",
    "\n",
    "```python\n",
    "sklearn.svm.LinearSVC(multi_class='ovr')\n",
    "\n",
    "sklearn.linear_model.LogisticRegression(multi_class='ovr')\n",
    "\n",
    "sklearn.multiclass.OneVsRestClassifier\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, n_classes=3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With LogisticRegression (inbuilt one versus all):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(multi_class='ovr')\n",
    "lr.fit(X, y)\n",
    "y_predict = lr.predict(X)\n",
    "\n",
    "print(np.unique(y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One versus All + LogisticRegression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "lr = LogisticRegression()\n",
    "ovr = OneVsRestClassifier(lr)\n",
    "ovr.fit(X, y)\n",
    "\n",
    "y_predict = ovr.predict(X)\n",
    "\n",
    "print(np.unique(y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "## 1.3.2 One-vs-One"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train $C^2_K$ classifiers kind of:\n",
    "$$a_{ij}(x); i \\neq j; i,j = 1, \\dots K,$$\n",
    "\n",
    "Each of which is trained on $X_{ij} = \\left[ (x_l, y_l) \\in X| y_n = i \\text{   or   } y_n = j \\right]$.\n",
    "\n",
    "Answer on new sample calculates as follows: \n",
    "\n",
    "$$a(x) = argmax_{k \\in 1, \\dots K} \\sum\\limits_{i=1}^{l}\\sum\\limits_{i\\neq j} I(a_{ij}(x)=k)$$\n",
    "\n",
    "```python\n",
    "sklearn.svm.SVC\n",
    "\n",
    "sklearn.multiclass.OneVsOneClassifier\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With SVM (inline one versus one):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(decision_function_shape='ovo')\n",
    "svm.fit(X, y)\n",
    "\n",
    "y_predict = svm.predict(X)\n",
    "\n",
    "print(np.unique(y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One versus One + SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "svm = SVC()\n",
    "ovo = OneVsOneClassifier(svm)\n",
    "ovo.fit(X, y)\n",
    "\n",
    "y_predict = ovo.predict(X)\n",
    "\n",
    "print(np.unique(y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Metrics for multiclass classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For multiclass classification, there are the same metrics as for binary classification. Most of them are based on TP, TN, FP, FN. But the final metrics, like precision and etc., can be calculsted in $2$ special ways:\n",
    "* micro: calculate TP, TN, ... for each class, take mean, calculate final metrics (presicion, recall etc.)\n",
    "* macro: calculate presicion, recall, etc for each class, take mean. \n",
    "\n",
    "**Examples:**\n",
    "\n",
    "* micro-precision: $\\frac{\\overline{TP}}{\\overline{TP}+\\overline{FP}}$, where $\\overline{TP} = \\frac{1}{K}\\sum\\limits_{k=1}^{K}TP_k$\n",
    "* macro-precision: $precision = \\frac{1}{K}\\sum\\limits_{k=1}^{K}precision_k,$ where $precision_k = \\frac{TP_k}{TP_k+FP_k}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** if the classes are not balanced then in micro type of calculating metrics classes with little power will hardly contribute to the final result. In the macro-averaging there is no such a problem. \n",
    "\n",
    "```python\n",
    "sklearn.metrics.roc_auc_score(average='micro')\n",
    "sklearn.metrics.roc_auc_score(average='macro')\n",
    "sklearn.metrics.recall_score(average='micro')\n",
    "sklearn.metrics.recall_score(average='macro')\n",
    "sklearn.metrics.precision_score(average='micro')\n",
    "sklearn.metrics.precision_score(average='macro')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, precision_score\n",
    "\n",
    "recall_score(y, y_predict, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8901173556501455"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y, y_predict, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
